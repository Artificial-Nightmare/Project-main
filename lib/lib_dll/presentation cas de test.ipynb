{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16de1796",
   "metadata": {},
   "source": [
    "# CAS DE TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e641130",
   "metadata": {},
   "source": [
    "# TEST LINEAIRE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73492597",
   "metadata": {},
   "source": [
    "classification binaire simple SUCCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dfdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the directory of the current script\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append the path to the DLL to the system's search path\n",
    "dll_path = os.path.join(current_dir, 'liblinear_classification.dll')\n",
    "sys.path.append(dll_path)\n",
    "dll = ctypes.cdll.LoadLibrary(dll_path)\n",
    "\n",
    "# Définition des types de données pour la fonction rosenblatt\n",
    "dll.rosenblatt.argtypes = [np.ctypeslib.ndpointer(dtype=np.double, ndim=2, flags='C_CONTIGUOUS'),\n",
    "                           np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags='C_CONTIGUOUS'),\n",
    "                           ctypes.c_int, ctypes.c_int, ctypes.c_double, ctypes.c_int,\n",
    "                           np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags='C_CONTIGUOUS'),\n",
    "                           ctypes.c_int]\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# n'oubliez pas de mettre le dtype=np.float64 !\n",
    "X = np.array([\n",
    "      [1, 1],\n",
    "      [2, 3],\n",
    "      [3, 3]\n",
    "], dtype=np.float64)\n",
    "Y = np.array([\n",
    "      1,\n",
    "      -1,\n",
    "      -1\n",
    "],dtype=np.float64).flatten()\n",
    "learning_rate = 0.1\n",
    "max_iterations = 100\n",
    "# Centrage et réduction des données\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# Créer un tableau de sortie pour les poids entraînés\n",
    "w = np.zeros((X.shape[1] + 1) * 2, dtype=np.float64)\n",
    "\n",
    "# Appeler la fonction rosenblatt avec un pointeur vers le tableau de sortie\n",
    "dll.rosenblatt(X, Y, X.shape[0], X.shape[1], learning_rate, max_iterations, w,2)\n",
    "\n",
    "for i in range(2):  # Remplacez 2 par le nombre de classes que vous voulez\n",
    "    print(f\"Poids pour la classe {i} : {w[i*(X.shape[1] + 1):(i+1)*(X.shape[1] + 1)]}\")\n",
    "\n",
    "# Affichage des données\n",
    "plt.scatter(X[0, 0], X[0, 1], color='blue')\n",
    "plt.scatter(X[1:3,0], X[1:3,1], color='red')\n",
    "# Affichage de la droite de séparation\n",
    "x = np.linspace(-1, 4, 100)\n",
    "for i in range(2):  # Remplacez 2 par le nombre de classes que vous voulez\n",
    "    w_i = w[i*(X.shape[1] + 1):(i+1)*(X.shape[1] + 1)]\n",
    "    y = -(w_i[0] * x + w_i[2]) / w_i[1]\n",
    "    plt.plot(x, y, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b8ec6f",
   "metadata": {},
   "source": [
    "classification binaire SUCCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619a30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the directory of the current script\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append the path to the DLL to the system's search path\n",
    "dll_path = os.path.join(current_dir, 'liblinear_classification.dll')\n",
    "sys.path.append(dll_path)\n",
    "dll = ctypes.cdll.LoadLibrary(dll_path)\n",
    "\n",
    "# Définition des types de données pour la fonction rosenblatt\n",
    "dll.rosenblatt.argtypes = [np.ctypeslib.ndpointer(dtype=np.double, ndim=2, flags='C_CONTIGUOUS'),\n",
    "                           np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags='C_CONTIGUOUS'),\n",
    "                           ctypes.c_int, ctypes.c_int, ctypes.c_double, ctypes.c_int,\n",
    "                           np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags='C_CONTIGUOUS'),\n",
    "                           ctypes.c_int]\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# pas oublier de mettre le dtype=np.float64 !\n",
    "X = np.concatenate([np.random.random((50,2)) * 1 + np.array([1, 1]), np.random.random((50,2)) * 1 + np.array([2, 2])], dtype=np.float64)\n",
    "Y = np.concatenate([np.ones((50, 1)), np.ones((50, 1)) * -1.0], dtype=np.float64).flatten()\n",
    "learning_rate = 0.2\n",
    "max_iterations = 100\n",
    "# Centrage et réduction des données\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "\n",
    "# Créer un tableau de sortie pour les poids entraînés\n",
    "w = np.zeros((X.shape[1] + 1) * 2, dtype=np.float64)  # Remplacez 2 par le nombre de classes que vous voulez\n",
    "\n",
    "# Appeler la fonction rosenblatt avec un pointeur vers le tableau de sortie\n",
    "dll.rosenblatt(X, Y, X.shape[0], X.shape[1], learning_rate, max_iterations, w, 2)  # Remplacez 2 par le nombre de classes que vous voulez\n",
    "\n",
    "# Affichage des poids pour chaque classe\n",
    "for i in range(2):  # Remplacez 2 par le nombre de classes que vous voulez\n",
    "    print(f\"Poids pour la classe {i} : {w[i*(X.shape[1] + 1):(i+1)*(X.shape[1] + 1)]}\")\n",
    "\n",
    "# Affichage des données\n",
    "plt.scatter(X[0:50, 0], X[0:50, 1], color='blue')\n",
    "plt.scatter(X[50:100,0], X[50:100,1], color='red') \n",
    "\n",
    "# Affichage de la droite de séparation\n",
    "\n",
    "x = np.linspace(-2, 2, 100)\n",
    "for i in range(2):  # Remplacez 2 par le nombre de classes que vous voulez\n",
    "    w_i = w[i*(X.shape[1] + 1):(i+1)*(X.shape[1] + 1)]\n",
    "    y = -(w_i[0] * x + w_i[2]) / w_i[1]\n",
    "    plt.plot(x, y, color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8468887e",
   "metadata": {},
   "source": [
    "test multi class ECHEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965962dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the directory of the current script\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append the path to the DLL to the system's search path\n",
    "dll_path = os.path.join(current_dir, 'liblinear_classification.dll')\n",
    "sys.path.append(dll_path)\n",
    "dll = ctypes.cdll.LoadLibrary(dll_path)\n",
    "\n",
    "# Définition des types de données pour la fonction rosenblatt\n",
    "dll.rosenblatt.argtypes = [np.ctypeslib.ndpointer(dtype=np.double, ndim=2, flags='C_CONTIGUOUS'),\n",
    "                           np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags='C_CONTIGUOUS'),\n",
    "                           ctypes.c_int, ctypes.c_int, ctypes.c_double, ctypes.c_int,\n",
    "                           np.ctypeslib.ndpointer(dtype=np.double, ndim=1, flags='C_CONTIGUOUS'),\n",
    "                           ctypes.c_int]\n",
    "\n",
    "# Exemple d'utilisation\n",
    "# n'oubliez pas de mettre le dtype=np.float64 !\n",
    "X = np.random.random((500, 2)) * 2.0 - 1.0\n",
    "Y = np.array([[1, 0, 0] if -p[0] - p[1] - 0.5 > 0 and p[1] < 0 and p[0] - p[1] - 0.5 < 0 else \n",
    "              [0, 1, 0] if -p[0] - p[1] - 0.5 < 0 and p[1] > 0 and p[0] - p[1] - 0.5 < 0 else \n",
    "              [0, 0, 1] if -p[0] - p[1] - 0.5 < 0 and p[1] < 0 and p[0] - p[1] - 0.5 > 0 else \n",
    "              [0, 0, 0]for p in X], dtype=np.float64)\n",
    "\n",
    "Xp = X.astype(np.float64)\n",
    "Yp = Y.flatten().astype(np.float64)\n",
    "\n",
    "learning_rate = 0.001\n",
    "max_iterations = 20000\n",
    "# Centrage et réduction des données\n",
    "Xp = (Xp - np.mean(Xp, axis=0)) / np.std(Xp, axis=0)\n",
    "\n",
    "# Créer un tableau de sortie pour les poids entraînés\n",
    "w = np.zeros((Xp.shape[1] + 1) * 3, dtype=np.float64)  # Remplacez 3 par le nombre de classes que vous voulez\n",
    "\n",
    "# Appeler la fonction rosenblatt avec un pointeur vers le tableau de sortie\n",
    "dll.rosenblatt(Xp, Yp, Xp.shape[0], Xp.shape[1], learning_rate, max_iterations, w, 3)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"Poids pour la classe {i} : {w[i*(Xp.shape[1] + 1):(i+1)*(Xp.shape[1] + 1)]}\")\n",
    "\n",
    "plt.scatter(X[Y[:, 0] == 1, 0], X[Y[:, 0] == 1, 1], color='blue')\n",
    "plt.scatter(X[Y[:, 1] == 1, 0], X[Y[:, 1] == 1, 1], color='red')\n",
    "plt.scatter(X[Y[:, 2] == 1, 0], X[Y[:, 2] == 1, 1], color='green')\n",
    "\n",
    "# Affichage des droites de séparation\n",
    "x = np.linspace(-2, 2, 100)\n",
    "for i in range(3):\n",
    "    w_i = w[i*(Xp.shape[1] + 1):(i+1)*(Xp.shape[1] + 1)]\n",
    "    y = -(w_i[0] * x + w_i[2]) / w_i[1]\n",
    "    plt.plot(x, y, color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4437386",
   "metadata": {},
   "source": [
    "# TEST PMC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b73f911",
   "metadata": {},
   "source": [
    "probleme de XOR SUCCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the directory of the current script\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append the path to the DLL to the system's search path\n",
    "dll_path = os.path.join(current_dir, 'perceptron_multi_couche.dll')\n",
    "sys.path.append(dll_path)\n",
    "\n",
    "# Load the DLL\n",
    "mlp_dll = ctypes.cdll.LoadLibrary(dll_path)\n",
    "\n",
    "# Définition des types de données\n",
    "mlp_dll.createMLP.restype = ctypes.c_void_p\n",
    "mlp_dll.createMLP.argtypes = [ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n",
    "mlp_dll.deleteMLP.argtypes = [ctypes.c_void_p]\n",
    "mlp_dll.predict.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_double), ctypes.c_int, ctypes.c_bool, ctypes.POINTER(ctypes.c_double), ctypes.c_int]\n",
    "mlp_dll.train.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_double), ctypes.POINTER(ctypes.c_double), ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.c_bool, ctypes.c_int, ctypes.c_double]\n",
    "\n",
    "# Création du MLP avec 2 entrées, 2 neurones cachés et 1 sortie\n",
    "npl = np.array([2,2, 1], dtype=np.int32)\n",
    "mlp_ptr = mlp_dll.createMLP(npl.ctypes.data_as(ctypes.POINTER(ctypes.c_int)), npl.size)\n",
    "\n",
    "# Entraînement du MLP sur le XOR\n",
    "samples_inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.double)\n",
    "samples_expected_outputs = np.array([[0], [1], [1], [0]], dtype=np.double)\n",
    "mlp_dll.train(mlp_ptr,\n",
    "               samples_inputs.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "               samples_expected_outputs.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "               samples_inputs.shape[0], samples_inputs.shape[1], samples_expected_outputs.shape[1],\n",
    "               True,400000, 0.05)\n",
    "\n",
    "# Test du MLP sur le XOR\n",
    "input = np.zeros(2, dtype=np.double)\n",
    "output = np.zeros(1, dtype=np.double)\n",
    "for i in range(samples_inputs.shape[0]):\n",
    "    input[0] = samples_inputs[i, 0]\n",
    "    input[1] = samples_inputs[i, 1]\n",
    "    mlp_dll.predict(mlp_ptr, \n",
    "                    input.ctypes.data_as(ctypes.POINTER(ctypes.c_double)), \n",
    "                    input.size, \n",
    "                    True, \n",
    "                    output.ctypes.data_as(ctypes.POINTER(ctypes.c_double)), \n",
    "                    output.size)\n",
    "    print(f\"[{int(input[0])}, {int(input[1])}] = {output[0]}\")\n",
    "\n",
    "# Suppression du MLP\n",
    "mlp_dll.deleteMLP(mlp_ptr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c740be",
   "metadata": {},
   "source": [
    "test corss classification SUCCES ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c5909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the directory of the current script\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append the path to the DLL to the system's search path\n",
    "dll_path = os.path.join(current_dir, 'perceptron_multi_couche.dll')\n",
    "sys.path.append(dll_path)\n",
    "\n",
    "# Load the DLL\n",
    "mlp_dll = ctypes.cdll.LoadLibrary(dll_path)\n",
    "\n",
    "# Définition des types de données\n",
    "mlp_dll.createMLP.restype = ctypes.c_void_p\n",
    "mlp_dll.createMLP.argtypes = [ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n",
    "mlp_dll.deleteMLP.argtypes = [ctypes.c_void_p]\n",
    "mlp_dll.predict.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_double), ctypes.c_int, ctypes.c_bool, ctypes.POINTER(ctypes.c_double), ctypes.c_int]\n",
    "mlp_dll.train.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_double), ctypes.POINTER(ctypes.c_double), ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.c_bool, ctypes.c_int, ctypes.c_double]\n",
    "\n",
    "# Création du MLP avec 2 entrées, 2 neurones cachés et 1 sortie\n",
    "npl = np.array([2,4, 1], dtype=np.int32)\n",
    "mlp_ptr = mlp_dll.createMLP(npl.ctypes.data_as(ctypes.POINTER(ctypes.c_int)), npl.size)\n",
    "\n",
    "X = np.random.random((500, 2)) * 2.0 - 1.0\n",
    "samples_inputs = np.array(X, dtype=np.double)\n",
    "Y = np.array([1 if abs(p[0]) <= 0.3 or abs(p[1]) <= 0.3 else -1 for p in X])\n",
    "samples_expected_outputs = np.array(Y, dtype=np.double)\n",
    "mlp_dll.train(mlp_ptr,\n",
    "               samples_inputs.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "               samples_expected_outputs.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "               samples_inputs.shape[0], samples_inputs.shape[1], 1,\n",
    "               True, 7500000, 0.02)\n",
    "\n",
    "\n",
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "input = np.zeros(input_size, dtype=np.double)\n",
    "output = np.zeros(output_size, dtype=np.double)\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "for i in range(samples_inputs.shape[0]):\n",
    "    input[0] = samples_inputs[i, 0]\n",
    "    input[1] = samples_inputs[i, 1]\n",
    "    mlp_dll.predict(mlp_ptr, \n",
    "                    input.ctypes.data_as(ctypes.POINTER(ctypes.c_double)), \n",
    "                    input.size, \n",
    "                    True, \n",
    "                    output.ctypes.data_as(ctypes.POINTER(ctypes.c_double)), \n",
    "                    output.size)\n",
    "    expected_class = int(samples_expected_outputs[i])\n",
    "    predicted_class = 1 if output[0] >= 0.5 else -1\n",
    "    print(f\"[{input[0]}, {input[1]}] Expected Class: {expected_class}, Predicted Class: {predicted_class}\")\n",
    "    \n",
    "    if expected_class == predicted_class:\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = (correct_predictions / samples_inputs.shape[0]) * 100\n",
    "print(f\"\\nAccuracy: {accuracy}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Suppression du MLP\n",
    "mlp_dll.deleteMLP(mlp_ptr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e000e0c",
   "metadata": {},
   "source": [
    "test multi cross a voir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f47bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the directory of the current script\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append the path to the DLL to the system's search path\n",
    "dll_path = os.path.join(current_dir, 'perceptron_multi_couche.dll')\n",
    "sys.path.append(dll_path)\n",
    "\n",
    "# Load the DLL\n",
    "mlp_dll = ctypes.cdll.LoadLibrary(dll_path)\n",
    "\n",
    "# Définition des types de données\n",
    "mlp_dll.createMLP.restype = ctypes.c_void_p\n",
    "mlp_dll.createMLP.argtypes = [ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n",
    "mlp_dll.deleteMLP.argtypes = [ctypes.c_void_p]\n",
    "mlp_dll.predict.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_double), ctypes.c_int, ctypes.c_bool, ctypes.POINTER(ctypes.c_double), ctypes.c_int]\n",
    "mlp_dll.train.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_double), ctypes.POINTER(ctypes.c_double), ctypes.c_int, ctypes.c_int, ctypes.c_int, ctypes.c_bool, ctypes.c_int, ctypes.c_double]\n",
    "\n",
    "# Création du MLP avec 2 entrées, 2 neurones cachés et 1 sortie\n",
    "npl = np.array([2,32,4, 3], dtype=np.int32)\n",
    "mlp_ptr = mlp_dll.createMLP(npl.ctypes.data_as(ctypes.POINTER(ctypes.c_int)), npl.size)\n",
    "\n",
    "X = np.random.random((1000, 2)) * 2.0 - 1.0\n",
    "samples_inputs = np.array(X, dtype=np.double)\n",
    "Y = np.array([[1, 0, 0] if abs(p[0] % 0.5) <= 0.25 and abs(p[1] % 0.5) > 0.25 else [0, 1, 0] if abs(p[0] % 0.5) > 0.25 and abs(p[1] % 0.5) <= 0.25 else [0, 0, 1] for p in X])\n",
    "samples_expected_outputs = np.array(Y, dtype=np.double)\n",
    "mlp_dll.train(mlp_ptr,\n",
    "               samples_inputs.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "               samples_expected_outputs.ctypes.data_as(ctypes.POINTER(ctypes.c_double)),\n",
    "               samples_inputs.shape[0], samples_inputs.shape[1], 1,\n",
    "               True, 1000000, 0.01)\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = samples_inputs.shape[0]\n",
    "# Utilisation de la fonction \"predict\" pour prédire les sorties pour chaque entrée\n",
    "for i in range(samples_inputs.shape[0]):\n",
    "    input = samples_inputs[i]\n",
    "    output = np.zeros(samples_expected_outputs.shape[1], dtype=np.double)\n",
    "\n",
    "    mlp_dll.predict(mlp_ptr, \n",
    "                    input.ctypes.data_as(ctypes.POINTER(ctypes.c_double)), \n",
    "                    input.size, \n",
    "                    True, \n",
    "                    output.ctypes.data_as(ctypes.POINTER(ctypes.c_double)), \n",
    "                    output.size)\n",
    "\n",
    "    predicted_label = np.argmax(output)\n",
    "    expected_label = np.argmax(samples_expected_outputs[i])\n",
    "\n",
    "    print(\"Entrée :\", input)\n",
    "    print(\"Sortie prédite :\", output)\n",
    "    print(\"Sortie attendue :\", samples_expected_outputs[i])\n",
    "\n",
    "    if predicted_label == expected_label:\n",
    "        correct_predictions += 1\n",
    "\n",
    "    print()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(\"Taux de réussite : {:.2%}\".format(accuracy))     \n",
    "\n",
    "# Suppression du MLP\n",
    "mlp_dll.deleteMLP(mlp_ptr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f54e0",
   "metadata": {},
   "source": [
    "# BETA SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a24132",
   "metadata": {},
   "source": [
    "tentative de TEST SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e89c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the directory of the current script\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Append the path to the DLL to the system's search path\n",
    "dll_path = os.path.join(current_dir, 'SVM.dll')\n",
    "sys.path.append(dll_path)\n",
    "\n",
    "# Load the DLL\n",
    "svm_lib = ctypes.cdll.LoadLibrary(dll_path)\n",
    "\n",
    "# Définition des types de données pour les fonctions de la DLL\n",
    "svm_lib.trainSVM.argtypes = [\n",
    "    np.ctypeslib.ndpointer(dtype=np.float64, ndim=2, flags=\"C_CONTIGUOUS\"),\n",
    "    ctypes.c_size_t,\n",
    "    ctypes.c_size_t,\n",
    "    np.ctypeslib.ndpointer(dtype=np.float64, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    ctypes.POINTER(ctypes.c_double),\n",
    "    ctypes.c_int\n",
    "]\n",
    "svm_lib.trainSVM.restype = None\n",
    "\n",
    "svm_lib.predictSVM.argtypes = [\n",
    "    np.ctypeslib.ndpointer(dtype=np.float64, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    np.ctypeslib.ndpointer(dtype=np.float64, ndim=1, flags=\"C_CONTIGUOUS\"),\n",
    "    ctypes.c_double,\n",
    "    ctypes.c_size_t\n",
    "]\n",
    "svm_lib.predictSVM.restype = ctypes.c_int\n",
    "\n",
    "# Fonction pour entraîner le SVM avec l'algorithme du perceptron\n",
    "def trainSVM(trainingData, numIterations):\n",
    "    features = trainingData[:, :-1].astype(np.float64)\n",
    "    labels = trainingData[:, -1].astype(np.float64)\n",
    "\n",
    "    # Initialiser les poids et le biais à zéro\n",
    "    weights = np.zeros(features.shape[1], dtype=np.float64)\n",
    "    bias = ctypes.c_double(0.0)\n",
    "\n",
    "    svm_lib.trainSVM(features, features.shape[0], features.shape[1], weights, ctypes.byref(bias), numIterations)\n",
    "\n",
    "    return weights, bias.value\n",
    "\n",
    "# Fonction pour prédire la classe d'un exemple avec le SVM entraîné\n",
    "def predictSVM(features, weights, bias):\n",
    "    features = [float(x) for x in features]\n",
    "    return svm_lib.predictSVM(np.array(features, dtype=np.float64), weights, bias, len(features))\n",
    "\n",
    "\n",
    "trainingData = np.array([\n",
    "     [1, 1,1],\n",
    "      [2, 3,-1],\n",
    "      [3, 3,-1]\n",
    "])\n",
    "\n",
    "# Entraînement du SVM\n",
    "numIterations = 1000\n",
    "weights, bias = trainSVM(trainingData, numIterations)\n",
    "\n",
    "# Création des données de test\n",
    "testData = np.array([\n",
    "    [-1.5, -1.5],\n",
    "    [1.5, 1.5]\n",
    "])\n",
    "\n",
    "# Affichage des prédictions pour les données de test\n",
    "for i in range(testData.shape[0]):\n",
    "    features = testData[i]\n",
    "    prediction = predictSVM(features, weights, bias)\n",
    "    print(f\"Features: {features[0]}, {features[1]} => Output: {prediction}\")\n",
    "\n",
    "# Tracer les données d'entraînement\n",
    "plt.scatter(trainingData[:, 0], trainingData[:, 1], c=trainingData[:, 2], cmap='bwr')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Training Data')\n",
    "\n",
    "# Tracer les frontières de décision du SVM\n",
    "x_min, x_max = plt.xlim()\n",
    "y_min, y_max = plt.ylim()\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "Z = np.array([predictSVM([float(x), float(y)], weights, bias) for x, y in zip(xx.ravel(), yy.ravel())], dtype=np.float64)\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contour(xx, yy, Z, colors='black', linewidths=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94a258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
